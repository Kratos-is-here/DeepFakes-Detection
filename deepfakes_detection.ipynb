{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "test_dir = \"/kaggle/input/deepfake-detection-challenge/test_videos/\"\n",
    "\n",
    "test_videos = sorted([x for x in os.listdir(test_dir) if x[-4:] == \".mp4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/kaggle/input/xxxxxx/pytorchretinaface\")\n",
    "sys.path.insert(0, \"/kaggle/input/zzzzzz/mymodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from ./weights/Resnet50_Final.pth\n",
      "Missing keys:0\n",
      "Unused checkpoint keys:0\n",
      "Used keys:456\n",
      "Finished loading model!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage import transform as trans\n",
    "from data import cfg_mnet, cfg_re50\n",
    "from layers.functions.prior_box import PriorBox\n",
    "from utils.nms.py_cpu_nms import py_cpu_nms\n",
    "import cv2\n",
    "from models.retinaface import RetinaFace\n",
    "from utils.box_utils import decode, decode_landm\n",
    "import time\n",
    "\n",
    "arcface_src = np.array([\n",
    "  [122.5, 141.25],\n",
    "  [197.5, 141.25],\n",
    "  [160., 178.75],\n",
    "  [137.5, 225.25],\n",
    "  [182.5, 225.25] ], dtype=np.float32 ) # Ziyu\n",
    "arcface_src = np.expand_dims(arcface_src, axis=0)\n",
    "\n",
    "def estimate_norm(lmk, image_size = 112, mode='arcface'):\n",
    "    assert lmk.shape==(5,2)\n",
    "    tform = trans.SimilarityTransform()\n",
    "    lmk_tran = np.insert(lmk, 2, values=np.ones(5), axis=1)\n",
    "    min_M = []\n",
    "    min_index = []\n",
    "    min_error = float('inf') \n",
    "    if mode=='arcface':\n",
    "        src = arcface_src\n",
    "    else:\n",
    "        src = src_map[image_size]\n",
    "    for i in np.arange(src.shape[0]):\n",
    "        tform.estimate(lmk, src[i])\n",
    "    M = tform.params[0:2,:]\n",
    "    results = np.dot(M, lmk_tran.T)\n",
    "    results = results.T\n",
    "    error = np.sum(np.sqrt(np.sum((results - src[i]) ** 2,axis=1)))\n",
    "#         print(error)\n",
    "    if error< min_error:\n",
    "        min_error = error\n",
    "        min_M = M\n",
    "        min_index = i\n",
    "    return min_M, min_index\n",
    "\n",
    "def norm_crop(img, landmark, image_size=112, mode='arcface'):\n",
    "    M, pose_index = estimate_norm(landmark, image_size, mode)\n",
    "    warped = cv2.warpAffine(img,M, (image_size, image_size), borderValue = 0.0)\n",
    "    return warped\n",
    "\n",
    "def check_keys(model, pretrained_state_dict):\n",
    "    ckpt_keys = set(pretrained_state_dict.keys())\n",
    "    model_keys = set(model.state_dict().keys())\n",
    "    used_pretrained_keys = model_keys & ckpt_keys\n",
    "    unused_pretrained_keys = ckpt_keys - model_keys\n",
    "    missing_keys = model_keys - ckpt_keys\n",
    "    print('Missing keys:{}'.format(len(missing_keys)))\n",
    "    print('Unused checkpoint keys:{}'.format(len(unused_pretrained_keys)))\n",
    "    print('Used keys:{}'.format(len(used_pretrained_keys)))\n",
    "    assert len(used_pretrained_keys) > 0, 'load NONE from pretrained checkpoint'\n",
    "    return True\n",
    "\n",
    "\n",
    "def remove_prefix(state_dict, prefix):\n",
    "    ''' Old style model is stored with all names of parameters sharing common prefix 'module.' '''\n",
    "    f = lambda x: x.split(prefix, 1)[-1] if x.startswith(prefix) else x\n",
    "    return {f(key): value for key, value in state_dict.items()}\n",
    "\n",
    "\n",
    "def load_model(model, pretrained_path, load_to_cpu):\n",
    "    print('Loading pretrained model from {}'.format(pretrained_path))\n",
    "    if load_to_cpu:\n",
    "        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage)\n",
    "    else:\n",
    "        device = torch.cuda.current_device()\n",
    "        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage.cuda(device))\n",
    "    if \"state_dict\" in pretrained_dict.keys():\n",
    "        pretrained_dict = remove_prefix(pretrained_dict['state_dict'], 'module.')\n",
    "    else:\n",
    "        pretrained_dict = remove_prefix(pretrained_dict, 'module.')\n",
    "    check_keys(model, pretrained_dict)\n",
    "    model.load_state_dict(pretrained_dict, strict=False)\n",
    "    return model\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "cfg = cfg_re50\n",
    "cfg['pretrain']=False\n",
    "# net and model\n",
    "!cp /kaggle/input/xxxxxx/pytorchretinaface/weights ./ -rf\n",
    "net = RetinaFace(cfg=cfg, phase = 'test')\n",
    "net = load_model(net, './weights/Resnet50_Final.pth', False)\n",
    "net.eval()\n",
    "print('Finished loading model!')\n",
    "cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\")\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from model import WSDAN\n",
    "from util import  batch_augment\n",
    "tts=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.4479, 0.3744, 0.3473],std=[0.2537, 0.2502, 0.2424])\n",
    "        ])\n",
    "\n",
    "\n",
    "def extract_frames(data_path, method='cv2'):\n",
    "    \"\"\"Method to extract frames, either with ffmpeg or opencv. FFmpeg won't\n",
    "    start from 0 so we would have to rename if we want to keep the filenames\n",
    "    coherent.\"\"\"\n",
    "    data_path=test_dir+data_path\n",
    "    if method == 'cv2':\n",
    "        reader = cv2.VideoCapture(data_path)\n",
    "        outputbuff=[]\n",
    "        frames = 0\n",
    "        count = 0\n",
    "        resize=1\n",
    "        while reader.isOpened():\n",
    "            success, img = reader.read()\n",
    "            img_raw = img\n",
    "            if not success:\n",
    "                break\n",
    "            \n",
    "\n",
    "            frames +=1\n",
    "            if frames==1:\n",
    "                im_height, im_width, _ = img.shape\n",
    "                scale = torch.Tensor([img.shape[1], img.shape[0], img.shape[1], img.shape[0]])\n",
    "                scale = scale.to(device)\n",
    "                priorbox = PriorBox(cfg, image_size=(im_height, im_width))\n",
    "                priors = priorbox.forward()\n",
    "                priors = priors.to(device)\n",
    "                prior_data = priors.data\n",
    "                scale1 = torch.Tensor([img.shape[1], img.shape[0], img.shape[1], img.shape[0],\n",
    "                               img.shape[1], img.shape[0], img.shape[1], img.shape[0],\n",
    "                               img.shape[1], img.shape[0]])\n",
    "                scale1 = scale1.to(device)\n",
    "            if frames%10==0:\n",
    "                img = img.astype(np.int8)\n",
    "                img -= (104, 117, 123)\n",
    "                img = img.transpose(2, 0, 1)\n",
    "                img = torch.from_numpy(img).unsqueeze(0)\n",
    "                img=img.to(device,dtype=torch.float32)\n",
    "                loc, conf, landms = net(img)\n",
    "                boxes = decode(loc.data.squeeze(0), prior_data, cfg['variance'])\n",
    "                boxes = boxes * scale / resize\n",
    "                boxes = boxes.cpu().numpy()\n",
    "                scores = conf.squeeze(0).data.cpu().numpy()[:, 1]\n",
    "                landms = decode_landm(landms.data.squeeze(0), prior_data, cfg['variance'])\n",
    "                landms = landms * scale1 / resize\n",
    "                landms = landms.cpu().numpy()\n",
    "                inds = np.where(scores > 0.8)[0]\n",
    "                if inds.shape[0]==0:\n",
    "                    continue\n",
    "                boxes = boxes[inds]\n",
    "                landms = landms[inds]\n",
    "                scores = scores[inds]\n",
    "                areas = scores\n",
    "                for it in range(areas.shape[0]):\n",
    "                    areas[it] = (boxes[it][3]-boxes[it][1])*(boxes[it][2]-boxes[it][0])\n",
    "                order = areas.argsort()[::-1][:1]\n",
    "                boxes = boxes[order]\n",
    "                landms = landms[order]\n",
    "                scores = scores[order]\n",
    "                landmarks = landms.reshape(5,2).astype(np.int)\n",
    "                img=norm_crop(img_raw,landmarks,image_size=320)\n",
    "                aligned=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "                outputbuff.append(aligned)\n",
    "                count+=1\n",
    "                if count==20:\n",
    "                    break\n",
    "\n",
    "        reader.release()\n",
    "        return outputbuff\n",
    "\n",
    "def predict_on_video_set(video_paths,model,model2):\n",
    "    predictions = []\n",
    "    for num in range(len(video_paths)):\n",
    "        try:\n",
    "            stime=time.time()\n",
    "            frames=extract_frames( video_paths[num])\n",
    "            frames=torch.cat([tts(i).unsqueeze(0) for i in  frames])\n",
    "            images=frames.view(-1,3,320,320).cuda()\n",
    "            print(time.time()-stime)\n",
    "            y_pred_raw, _,_ = model(images)\n",
    "            logits=torch.mean(F.softmax(y_pred_raw,dim=1),dim=0)\n",
    "            pred=logits[1].item()\n",
    "            images_b=F.interpolate(images,size=300,mode='bilinear')\n",
    "            y_pred_raw2, _,_ = model2(images_b)\n",
    "            logits2=torch.mean(F.softmax(y_pred_raw2,dim=1),dim=0)\n",
    "            pred2=logits2[1].item()\n",
    "            pred=(pred*0.7+pred2*0.3)\n",
    "            if pred>0.99:\n",
    "                pred=0.99\n",
    "            if pred<0.01:\n",
    "                pred=0.01\n",
    "            predictions.append(pred)\n",
    "            print(time.time()-stime,pred)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            predictions.append(0.5)            \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.665373802185059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.034860134124756 0.99\n",
      "5.503705263137817\n",
      "5.671620607376099 0.01\n",
      "4.896178722381592\n",
      "5.064361333847046 0.977482271194458\n",
      "4.7666802406311035\n",
      "4.934689283370972 0.01\n",
      "4.9326698780059814\n",
      "5.100247144699097 0.8670711398124694\n",
      "4.819392681121826\n",
      "4.987227201461792 0.17966733053326606\n",
      "4.812265634536743\n",
      "4.9797210693359375 0.99\n",
      "4.9670515060424805\n",
      "5.134676694869995 0.8401391416788101\n",
      "5.618688106536865\n",
      "5.7860424518585205 0.9727207183837889\n",
      "8.563059329986572\n",
      "8.730682373046875 0.015440514869987963\n",
      "5.04287052154541\n",
      "5.2107720375061035 0.01\n",
      "5.221963167190552\n",
      "5.389755725860596 0.6962168008089065\n",
      "4.878407955169678\n",
      "5.0458714962005615 0.9579584479331971\n",
      "5.250699520111084\n",
      "5.418254137039185 0.01\n",
      "5.127938508987427\n",
      "5.295492172241211 0.09253824520856142\n",
      "4.756957769393921\n",
      "4.924576282501221 0.99\n",
      "5.138733625411987\n",
      "5.306688547134399 0.8534526050090789\n",
      "5.051981687545776\n",
      "5.219717741012573 0.2148729108273983\n",
      "5.6937501430511475\n",
      "5.861142873764038 0.1021221837028861\n",
      "6.092857360839844\n",
      "6.260677337646484 0.9834924221038817\n",
      "5.158060550689697\n",
      "5.325582265853882 0.17506707459688187\n",
      "5.353938817977905\n",
      "5.521382093429565 0.99\n",
      "4.903411626815796\n",
      "5.0712034702301025 0.04312602682039141\n",
      "4.7748847007751465\n",
      "4.942352056503296 0.2653619572520256\n",
      "5.040711879730225\n",
      "5.20812463760376 0.08616519179195165\n",
      "5.014009237289429\n",
      "5.181680202484131 0.095040662586689\n",
      "5.492661714553833\n",
      "5.660145044326782 0.9785757780075073\n",
      "4.731006860733032\n",
      "4.898576498031616 0.01\n",
      "5.517205476760864\n",
      "5.684799432754517 0.16442127712070942\n",
      "4.744512319564819\n",
      "4.911949396133423 0.99\n",
      "6.084060907363892\n",
      "6.251615762710571 0.99\n",
      "4.990560293197632\n",
      "5.157907962799072 0.01\n",
      "5.04128623008728\n",
      "5.209551095962524 0.8817164838314056\n",
      "4.871428728103638\n",
      "5.039130449295044 0.8752940952777861\n",
      "5.103365898132324\n",
      "5.270711421966553 0.14514793740818277\n",
      "5.420740365982056\n",
      "5.5882344245910645 0.99\n",
      "5.1623547077178955\n",
      "5.330320358276367 0.804853418469429\n",
      "5.064424753189087\n",
      "5.232011795043945 0.05071852961555123\n",
      "5.686213731765747\n",
      "5.854506015777588 0.99\n",
      "5.178168773651123\n",
      "5.345650672912598 0.6574808105826377\n",
      "4.7540788650512695\n",
      "4.921826601028442 0.022800022476531012\n",
      "5.170381307601929\n",
      "5.33786416053772 0.99\n",
      "5.442781925201416\n",
      "5.610247611999512 0.03663603439927101\n",
      "4.967392683029175\n",
      "5.134915351867676 0.01\n",
      "5.031138181686401\n",
      "5.199198484420776 0.9376767754554749\n",
      "5.820496320724487\n",
      "5.988141059875488 0.39667007029056545\n",
      "5.650418996810913\n",
      "5.817962646484375 0.8286948263645171\n",
      "5.382571458816528\n",
      "5.550279140472412 0.01\n",
      "5.054914951324463\n",
      "5.222347736358643 0.8177336990833282\n",
      "4.940039157867432\n",
      "5.107572317123413 0.22150710523128508\n",
      "4.830944299697876\n",
      "4.9982569217681885 0.01\n",
      "4.997284889221191\n",
      "5.16499137878418 0.01\n",
      "5.066279172897339\n",
      "5.234067916870117 0.9846457183361053\n",
      "5.141489505767822\n",
      "5.309341192245483 0.01\n",
      "4.956028461456299\n",
      "5.123580455780029 0.01\n",
      "4.894503116607666\n",
      "5.062037944793701 0.06085541694410494\n",
      "4.882485866546631\n",
      "5.050003290176392 0.01\n",
      "4.7557196617126465\n",
      "4.923334121704102 0.9490538835525513\n",
      "5.120543479919434\n",
      "5.287994623184204 0.08479803148657084\n",
      "4.875514268875122\n",
      "5.043082237243652 0.01\n",
      "5.633328914642334\n",
      "5.800964593887329 0.417924827337265\n",
      "4.986940860748291\n",
      "5.1545233726501465 0.01\n",
      "5.58202600479126\n",
      "5.7495574951171875 0.945041400194168\n",
      "5.409441232681274\n",
      "5.577306509017944 0.014358256648120004\n",
      "5.194767236709595\n",
      "5.36223292350769 0.01\n",
      "5.5393431186676025\n",
      "5.706768035888672 0.9846554458141327\n",
      "5.691662788391113\n",
      "5.859095335006714 0.9755021929740906\n",
      "4.810332536697388\n",
      "4.977790832519531 0.99\n",
      "4.810916423797607\n",
      "4.978543996810913 0.01\n",
      "4.82698130607605\n",
      "4.9944844245910645 0.08990715499967336\n",
      "4.822062253952026\n",
      "4.989430665969849 0.01\n",
      "5.311628341674805\n",
      "5.479292392730713 0.07579184754285961\n",
      "5.097978591918945\n",
      "5.265506029129028 0.7510908991098403\n",
      "5.12030029296875\n",
      "5.288203239440918 0.9808992683887481\n",
      "5.143044471740723\n",
      "5.310774803161621 0.9707624435424804\n",
      "5.017916679382324\n",
      "5.185304880142212 0.99\n",
      "5.594443082809448\n",
      "5.7619946002960205 0.99\n",
      "4.994380474090576\n",
      "5.161919355392456 0.99\n",
      "4.978767156600952\n",
      "5.1461145877838135 0.01\n",
      "4.771495819091797\n",
      "4.938778400421143 0.041416913760986065\n",
      "4.931014776229858\n",
      "5.09842324256897 0.99\n",
      "6.859296083450317\n",
      "10.319855213165283 0.9846044301986694\n",
      "5.32509446144104\n",
      "5.492791652679443 0.99\n",
      "4.942815065383911\n",
      "5.110442638397217 0.99\n",
      "4.802196741104126\n",
      "4.969812393188477 0.24051278736442327\n",
      "5.328680992126465\n",
      "5.496240139007568 0.06317231282591819\n",
      "5.798181533813477\n",
      "5.965652227401733 0.99\n",
      "5.356963634490967\n",
      "5.524756908416748 0.06977797804865986\n",
      "5.158322095870972\n",
      "5.325976133346558 0.8101430416107177\n",
      "5.239924907684326\n",
      "5.40764856338501 0.47581703066825864\n",
      "4.980226755142212\n",
      "5.147727727890015 0.010175055637955665\n",
      "4.928929328918457\n",
      "5.0965375900268555 0.9776744306087494\n",
      "4.795653343200684\n",
      "4.963183403015137 0.030376383848488328\n",
      "5.310617446899414\n",
      "5.478240013122559 0.6539792872965335\n",
      "5.226976633071899\n",
      "5.394397974014282 0.03163918582722544\n",
      "5.721638441085815\n",
      "5.889178276062012 0.99\n",
      "5.761173248291016\n",
      "5.928837060928345 0.23352342694997785\n",
      "5.434263706207275\n",
      "5.601862192153931 0.09728445149958133\n",
      "5.796316146850586\n",
      "5.963768005371094 0.99\n",
      "5.26879096031189\n",
      "5.436837196350098 0.99\n",
      "5.9746904373168945\n",
      "6.142456531524658 0.226778669655323\n",
      "6.067967176437378\n",
      "6.235768556594849 0.99\n",
      "5.184869766235352\n",
      "5.3524510860443115 0.99\n",
      "5.016653537750244\n",
      "5.184424877166748 0.03206813707947731\n",
      "4.905964612960815\n",
      "5.07347559928894 0.99\n",
      "4.898373126983643\n",
      "5.06610631942749 0.01\n",
      "5.23715353012085\n",
      "5.404668092727661 0.9513330578804016\n",
      "5.4668660163879395\n",
      "5.634698867797852 0.7228435754776001\n",
      "5.895351886749268\n",
      "6.062931299209595 0.10166982703740358\n",
      "5.75247597694397\n",
      "5.920272588729858 0.01\n",
      "5.226728916168213\n",
      "5.394180059432983 0.6448821544647216\n",
      "5.396862745285034\n",
      "5.564375877380371 0.99\n",
      "4.8446900844573975\n",
      "5.0123536586761475 0.99\n",
      "4.978938579559326\n",
      "5.146492958068848 0.07280210144817828\n",
      "4.777877330780029\n",
      "4.94545578956604 0.99\n",
      "4.851106882095337\n",
      "5.018744707107544 0.99\n",
      "4.976390361785889\n",
      "5.143887042999268 0.99\n",
      "5.820355415344238\n",
      "5.987869739532471 0.08423977419734001\n",
      "4.681866407394409\n",
      "4.849384546279907 0.11863136049360036\n",
      "5.529658317565918\n",
      "5.697265625 0.99\n",
      "5.296430587768555\n",
      "5.464012145996094 0.09030680097639561\n",
      "4.9305455684661865\n",
      "5.09822678565979 0.01\n",
      "5.334229946136475\n",
      "5.501790523529053 0.862328279018402\n",
      "4.8808393478393555\n",
      "5.048584938049316 0.99\n",
      "5.252595663070679\n",
      "5.420261383056641 0.9344068825244903\n",
      "4.989898204803467\n",
      "5.157333135604858 0.99\n",
      "5.401408910751343\n",
      "5.569000005722046 0.99\n",
      "4.889688491821289\n",
      "5.0573203563690186 0.01\n",
      "4.85496973991394\n",
      "5.022500276565552 0.01\n",
      "5.5692222118377686\n",
      "5.736740827560425 0.08904458833858371\n",
      "5.511703729629517\n",
      "5.679640054702759 0.6389176636934281\n",
      "5.0990331172943115\n",
      "5.266505241394043 0.99\n",
      "5.2442097663879395\n",
      "5.411814451217651 0.8911016583442688\n",
      "5.417999267578125\n",
      "5.585684299468994 0.7571975737810135\n",
      "4.932297468185425\n",
      "5.099657773971558 0.8794177651405333\n",
      "5.547483682632446\n",
      "5.71509313583374 0.99\n",
      "5.167532205581665\n",
      "5.3350465297698975 0.6387853890657424\n",
      "4.9233691692352295\n",
      "5.090978384017944 0.9326589345932006\n",
      "5.085985422134399\n",
      "5.253582954406738 0.05879645757377147\n",
      "4.882987022399902\n",
      "5.050605297088623 0.11227388754487037\n",
      "5.495196580886841\n",
      "5.662754058837891 0.047399104645592154\n",
      "5.4134361743927\n",
      "5.580988168716431 0.03245528422121424\n",
      "5.150407314300537\n",
      "5.318004846572876 0.8892685890197753\n",
      "4.869357109069824\n",
      "5.036864280700684 0.02665614653378725\n",
      "4.864248752593994\n",
      "5.0319178104400635 0.9580985307693481\n",
      "5.208890199661255\n",
      "5.376427888870239 0.950222647190094\n",
      "5.14385461807251\n",
      "5.31151819229126 0.08928368724882602\n",
      "5.256664514541626\n",
      "5.424216032028198 0.99\n",
      "4.7681427001953125\n",
      "4.935636520385742 0.99\n",
      "5.026445388793945\n",
      "5.194065093994141 0.07787934560328721\n",
      "5.713313341140747\n",
      "5.881028652191162 0.8670236349105835\n",
      "4.821676969528198\n",
      "4.989211797714233 0.05918871680714801\n",
      "5.139857292175293\n",
      "5.307432413101196 0.01\n",
      "5.29262113571167\n",
      "5.46032452583313 0.99\n",
      "5.301999807357788\n",
      "5.46943998336792 0.99\n",
      "5.026731014251709\n",
      "5.194237947463989 0.6673503935337066\n",
      "4.763946533203125\n",
      "4.931644916534424 0.01\n",
      "5.005203723907471\n",
      "5.1727049350738525 0.065787810459733\n",
      "4.985246658325195\n",
      "5.155189037322998 0.18761275466531516\n",
      "4.917076587677002\n",
      "5.084770679473877 0.048777247225370954\n",
      "4.780090093612671\n",
      "4.947577953338623 0.99\n",
      "4.90334153175354\n",
      "5.0708582401275635 0.01\n",
      "5.670434236526489\n",
      "5.838014364242554 0.09640956572256983\n",
      "5.185595750808716\n",
      "5.353078842163086 0.783666980266571\n",
      "5.970718145370483\n",
      "6.138194561004639 0.9886672914028167\n",
      "5.55767297744751\n",
      "5.725284814834595 0.7956664025783539\n",
      "5.140345335006714\n",
      "5.307873249053955 0.0381631835153712\n",
      "7.218998193740845\n",
      "10.155111312866211 0.9715883374214171\n",
      "5.170229434967041\n",
      "5.337797403335571 0.25848597958683966\n",
      "5.332819700241089\n",
      "5.500446796417236 0.06476050219498575\n",
      "5.7346110343933105\n",
      "5.902322053909302 0.07360771338571795\n",
      "5.316919326782227\n",
      "5.484521865844727 0.99\n",
      "4.844789743423462\n",
      "5.012462377548218 0.19734305962920187\n",
      "5.882946252822876\n",
      "6.050602912902832 0.9199150502681732\n",
      "5.280591011047363\n",
      "5.4480531215667725 0.99\n",
      "5.116769313812256\n",
      "5.2843616008758545 0.01\n",
      "5.0117363929748535\n",
      "5.1792707443237305 0.01\n",
      "4.952468156814575\n",
      "5.12047266960144 0.14850715696811675\n",
      "5.095637559890747\n",
      "5.263221979141235 0.8737436532974242\n",
      "5.164463996887207\n",
      "5.33198356628418 0.015516591956838965\n",
      "5.8780837059021\n",
      "6.04545521736145 0.02094765107613057\n",
      "5.683833360671997\n",
      "5.851684808731079 0.01\n",
      "4.942044973373413\n",
      "5.109714984893799 0.99\n",
      "4.933712005615234\n",
      "5.1014790534973145 0.07179101957008242\n",
      "5.099566221237183\n",
      "5.267329931259155 0.8092285245656967\n",
      "7.528691053390503\n",
      "10.305129051208496 0.9726564526557921\n",
      "4.94897723197937\n",
      "5.116525173187256 0.01\n",
      "4.916705131530762\n",
      "5.084348678588867 0.01725653708563186\n",
      "5.042340993881226\n",
      "5.210093259811401 0.99\n",
      "4.818987131118774\n",
      "4.986509084701538 0.99\n",
      "4.883941888809204\n",
      "5.051631927490234 0.020685267040971667\n",
      "5.4647722244262695\n",
      "5.63239860534668 0.01\n",
      "5.072052955627441\n",
      "5.239616632461548 0.99\n",
      "4.824090480804443\n",
      "4.991605281829834 0.01\n",
      "5.064568042755127\n",
      "5.232208728790283 0.0556482728687115\n",
      "4.939099073410034\n",
      "5.107182264328003 0.8734400510787963\n",
      "5.1527299880981445\n",
      "5.320723295211792 0.01\n",
      "5.043301820755005\n",
      "5.210752248764038 0.01\n",
      "5.883379697799683\n",
      "6.050954580307007 0.99\n",
      "5.33900260925293\n",
      "5.506537437438965 0.99\n",
      "7.015872955322266\n",
      "10.278075695037842 0.9628652989864349\n",
      "4.899817705154419\n",
      "5.067435264587402 0.99\n",
      "4.965531349182129\n",
      "5.133015871047974 0.7456579953432082\n",
      "4.765897989273071\n",
      "4.933668613433838 0.01\n",
      "5.106131076812744\n",
      "5.273937702178955 0.8794781565666198\n",
      "4.888479232788086\n",
      "5.055964231491089 0.027289306302554904\n",
      "5.876887559890747\n",
      "6.044320106506348 0.02965788684232393\n",
      "5.082379102706909\n",
      "5.249989748001099 0.99\n",
      "5.058979034423828\n",
      "5.2265870571136475 0.01\n",
      "5.187302350997925\n",
      "5.354914903640747 0.8141622424125671\n",
      "4.934642553329468\n",
      "5.10219144821167 0.01\n",
      "5.1743996143341064\n",
      "5.341865301132202 0.99\n",
      "4.869757413864136\n",
      "5.037188529968262 0.01\n",
      "4.937715291976929\n",
      "5.105420827865601 0.025004202935087958\n",
      "5.108546733856201\n",
      "5.276017904281616 0.01\n",
      "4.817828893661499\n",
      "4.985440254211426 0.01\n",
      "4.8901519775390625\n",
      "5.0576698780059814 0.01\n",
      "8.043394088745117\n",
      "8.211041927337646 0.99\n",
      "5.707854747772217\n",
      "5.875354528427124 0.7963219612836837\n",
      "5.500336170196533\n",
      "5.667744398117065 0.99\n",
      "4.987355947494507\n",
      "5.154960632324219 0.029262481455225496\n",
      "5.335770606994629\n",
      "5.503652811050415 0.053789885900914665\n",
      "4.810693979263306\n",
      "4.9781365394592285 0.01\n",
      "4.818915367126465\n",
      "4.986425399780273 0.01\n",
      "5.763035535812378\n",
      "5.93048357963562 0.9468173623085021\n",
      "4.969816207885742\n",
      "5.137411832809448 0.8704812467098235\n",
      "5.288266181945801\n",
      "5.455920219421387 0.9823106348514556\n",
      "5.282894611358643\n",
      "5.4504618644714355 0.023355242703109978\n",
      "5.365343332290649\n",
      "5.533044338226318 0.9630268335342407\n",
      "5.653378486633301\n",
      "5.8211143016815186 0.6344656109809875\n",
      "7.135308742523193\n",
      "10.24187445640564 0.9723638772964477\n",
      "4.914319753646851\n",
      "5.081936836242676 0.13640846336929827\n",
      "5.073638916015625\n",
      "5.241161823272705 0.13398263952694833\n",
      "5.001812219619751\n",
      "5.1693596839904785 0.8071585357189177\n",
      "4.723974704742432\n",
      "4.891451597213745 0.01\n",
      "5.129121780395508\n",
      "5.297069549560547 0.07490139983128756\n",
      "5.7743613719940186\n",
      "5.941897630691528 0.9815719902515412\n",
      "5.55971884727478\n",
      "5.727095365524292 0.01\n",
      "6.035331726074219\n",
      "6.202703237533569 0.10231087803840637\n",
      "5.637068033218384\n",
      "5.804687976837158 0.958512830734253\n",
      "4.960554599761963\n",
      "5.128019332885742 0.99\n",
      "4.98084831237793\n",
      "5.148471832275391 0.1540329225361347\n",
      "4.775909900665283\n",
      "4.9433274269104 0.01\n",
      "4.904571771621704\n",
      "5.0722222328186035 0.9355368435382843\n",
      "5.13689112663269\n",
      "5.3044514656066895 0.8088395833969115\n",
      "5.458958864212036\n",
      "5.626559495925903 0.021545925288228317\n",
      "4.76765513420105\n",
      "4.935105800628662 0.01\n",
      "5.260145425796509\n",
      "5.427634954452515 0.33085129857063295\n",
      "4.977396488189697\n",
      "5.144941091537476 0.9122683465480803\n",
      "6.120378017425537\n",
      "6.287971019744873 0.06126420018263161\n",
      "5.152878284454346\n",
      "5.320338249206543 0.9848175764083862\n",
      "4.938294887542725\n",
      "5.105732202529907 0.01\n",
      "5.205434560775757\n",
      "5.372981309890747 0.99\n",
      "4.974148988723755\n",
      "5.141820669174194 0.99\n",
      "4.956336259841919\n",
      "5.1239776611328125 0.7548560619354248\n",
      "4.771372318267822\n",
      "4.938848495483398 0.015842366963624954\n",
      "4.799149036407471\n",
      "4.966701984405518 0.01\n",
      "5.637471675872803\n",
      "5.805239677429199 0.99\n",
      "4.895931005477905\n",
      "5.063504934310913 0.18460752964019775\n",
      "4.777570486068726\n",
      "4.945404291152954 0.99\n",
      "7.313726186752319\n",
      "10.130900859832764 0.9567866325378418\n",
      "7.2894110679626465\n",
      "10.002516984939575 0.99\n",
      "5.235049247741699\n",
      "5.402630805969238 0.8238961815834045\n",
      "6.832444906234741\n",
      "6.895709276199341 0.99\n",
      "5.6793389320373535\n",
      "5.84694766998291 0.8197843551635742\n",
      "5.30981183052063\n",
      "5.47740626335144 0.9734891295433044\n",
      "5.033045530319214\n",
      "5.200695514678955 0.8791790008544922\n",
      "4.748543977737427\n",
      "4.9159135818481445 0.2024235620163381\n",
      "4.813530206680298\n",
      "4.981074810028076 0.10630230568349361\n",
      "5.046886205673218\n",
      "5.214511871337891 0.0286214349887814\n",
      "5.093283653259277\n",
      "5.260694265365601 0.99\n",
      "5.278017044067383\n",
      "5.4455718994140625 0.8879533529281616\n",
      "5.063690423965454\n",
      "5.231480121612549 0.99\n",
      "4.765915155410767\n",
      "4.933677673339844 0.01\n",
      "4.937402248382568\n",
      "5.104902267456055 0.01651868098997511\n",
      "5.706929922103882\n",
      "5.874408721923828 0.99\n",
      "4.741227626800537\n",
      "4.908814191818237 0.03681632850784808\n",
      "4.735952615737915\n",
      "4.903594493865967 0.8766345977783202\n",
      "4.989681720733643\n",
      "5.157087326049805 0.9202170729637145\n",
      "5.101032257080078\n",
      "5.26858925819397 0.935544580221176\n",
      "4.9583799839019775\n",
      "5.125832557678223 0.06262591928243637\n",
      "5.716531991958618\n",
      "5.883937120437622 0.8876159667968749\n",
      "5.25316047668457\n",
      "5.420822620391846 0.01\n",
      "5.453232049942017\n",
      "5.620774030685425 0.99\n",
      "5.365147590637207\n",
      "5.532883405685425 0.99\n",
      "5.681717395782471\n",
      "5.849186658859253 0.8438267648220061\n",
      "5.128538608551025\n",
      "5.295980453491211 0.7900265216827392\n",
      "5.092970609664917\n",
      "5.260579347610474 0.8891113340854644\n",
      "5.59813117980957\n",
      "5.765643119812012 0.830606460571289\n",
      "5.569068193435669\n",
      "5.736634731292725 0.01\n",
      "4.718597173690796\n",
      "4.8862011432647705 0.99\n",
      "5.0144734382629395\n",
      "5.181863307952881 0.16208824720233678\n",
      "6.029556512832642\n",
      "6.197049617767334 0.99\n",
      "5.530688524246216\n",
      "5.6985650062561035 0.99\n",
      "6.017920970916748\n",
      "6.1855387687683105 0.26232005953788756\n",
      "5.870670557022095\n",
      "6.038146734237671 0.7709726452827452\n",
      "6.018359661102295\n",
      "6.186026573181152 0.16858995258808135\n",
      "4.989681005477905\n",
      "5.157333135604858 0.01\n",
      "5.82569694519043\n",
      "5.993382692337036 0.01\n",
      "7.168815851211548\n",
      "10.419488191604614 0.9881224811077118\n",
      "5.15378212928772\n",
      "5.321393728256226 0.99\n",
      "5.081651449203491\n",
      "5.249354124069214 0.01\n",
      "5.314262866973877\n",
      "5.481884479522705 0.8936510741710662\n",
      "6.431784391403198\n",
      "6.599575042724609 0.99\n",
      "5.396574020385742\n",
      "5.564132928848267 0.6380375578999519\n",
      "5.517400741577148\n",
      "5.6850059032440186 0.99\n",
      "5.0998406410217285\n",
      "5.267234563827515 0.9893208920955656\n",
      "4.91687536239624\n",
      "5.084277153015137 0.057301191454325814\n",
      "4.989170074462891\n",
      "5.156903982162476 0.06925608023593667\n",
      "5.05096697807312\n",
      "5.218565940856934 0.8073309779167175\n",
      "4.9168243408203125\n",
      "5.084815502166748 0.1312439233646728\n",
      "4.978611469268799\n",
      "5.146166086196899 0.99\n",
      "5.0211145877838135\n",
      "5.188897132873535 0.99\n",
      "5.507854700088501\n",
      "5.675572395324707 0.01\n",
      "5.984138488769531\n",
      "6.151897430419922 0.99\n",
      "5.7320215702056885\n",
      "5.899505615234375 0.062449753843247885\n",
      "5.529738426208496\n",
      "5.697438478469849 0.99\n",
      "5.53267765045166\n",
      "5.7003302574157715 0.9740889847278595\n",
      "5.236696243286133\n",
      "5.40419340133667 0.99\n",
      "4.963126182556152\n",
      "5.13074517250061 0.01\n",
      "4.961751461029053\n",
      "5.129510879516602 0.01495413004886359\n",
      "4.959452867507935\n",
      "5.1270527839660645 0.01\n",
      "5.134203672409058\n",
      "5.3016462326049805 0.7354754790663718\n",
      "5.1031653881073\n",
      "5.270687103271484 0.6813996523618698\n",
      "5.3643810749053955\n",
      "5.532238006591797 0.99\n",
      "5.307456731796265\n",
      "5.475110769271851 0.01\n",
      "5.155018091201782\n",
      "5.322466611862183 0.01\n",
      "4.854237079620361\n",
      "5.021820306777954 0.9391963243484496\n",
      "5.8010241985321045\n",
      "5.9684059619903564 0.011287285666912793\n",
      "4.981451749801636\n",
      "5.149040460586548 0.01\n",
      "4.992659330368042\n",
      "5.160096645355225 0.99\n",
      "5.19997763633728\n",
      "5.3674774169921875 0.01\n",
      "5.365838289260864\n",
      "5.533483028411865 0.01\n",
      "5.208317041397095\n",
      "5.375952959060669 0.40004898644983766\n",
      "5.0428993701934814\n",
      "5.210363864898682 0.99\n",
      "5.6381120681762695\n",
      "5.805542707443237 0.011609147901981488\n",
      "5.160158395767212\n",
      "5.327931642532349 0.99\n",
      "5.000504493713379\n",
      "5.168118715286255 0.01\n",
      "4.974299907684326\n",
      "5.141690492630005 0.01\n",
      "5.707006931304932\n",
      "5.874465465545654 0.1229335818439722\n",
      "5.67807674407959\n",
      "5.84553599357605 0.12959031388163567\n",
      "5.6584765911102295\n",
      "5.8260743618011475 0.99\n",
      "5.066732883453369\n",
      "5.234494686126709 0.6044294595718384\n",
      "5.5590314865112305\n",
      "5.726795196533203 0.318763156235218\n",
      "4.827191114425659\n",
      "4.994646072387695 0.040838489621091864\n",
      "4.917651653289795\n",
      "5.085189342498779 0.010712357936426997\n",
      "5.3411009311676025\n",
      "5.508824110031128 0.10267486050724983\n",
      "5.3994340896606445\n",
      "5.567307949066162 0.9510228872299193\n",
      "5.919087648391724\n",
      "6.086532354354858 0.99\n",
      "4.91245698928833\n",
      "5.080106019973755 0.017052358603541505\n",
      "5.391966342926025\n",
      "5.559613466262817 0.99\n",
      "5.360289812088013\n",
      "5.5282580852508545 0.42308346182107925\n",
      "5.654761791229248\n",
      "5.822285413742065 0.011372000013943761\n",
      "5.687845706939697\n",
      "5.855543851852417 0.02949314700672403\n",
      "6.958066463470459\n",
      "7.125768661499023 0.8264276683330536\n",
      "5.515580177307129\n",
      "5.68314266204834 0.9402449488639831\n",
      "5.166597366333008\n",
      "5.334240913391113 0.99\n",
      "5.778069019317627\n",
      "5.945852041244507 0.98648002743721\n",
      "5.014760971069336\n",
      "5.182284116744995 0.01\n",
      "5.426406145095825\n",
      "5.593955039978027 0.99\n",
      "5.968130826950073\n",
      "6.136110782623291 0.9306408882141113\n",
      "5.074415683746338\n",
      "5.242216348648071 0.04158232156187296\n",
      "5.35861873626709\n",
      "5.526240110397339 0.012878686306066811\n",
      "5.746577501296997\n",
      "5.914278030395508 0.99\n",
      "5.128478050231934\n",
      "5.295936107635498 0.8613657712936401\n",
      "5.1208415031433105\n",
      "5.288576602935791 0.017896485347955602\n",
      "4.91882061958313\n",
      "5.086092472076416 0.047187089840008405\n",
      "5.77172327041626\n",
      "5.93936824798584 0.01\n",
      "5.5484161376953125\n",
      "5.71601414680481 0.06553074633702635\n",
      "4.733664274215698\n",
      "4.901612997055054 0.1783723239786923\n",
      "5.731379985809326\n",
      "5.899162530899048 0.09793773796409368\n",
      "5.799033164978027\n",
      "5.966745376586914 0.9128688395023346\n",
      "5.584926128387451\n",
      "5.752620458602905 0.01\n",
      "5.119165897369385\n",
      "5.28704047203064 0.8051070362329483\n",
      "5.109622478485107\n",
      "5.277128458023071 0.11591169238090515\n",
      "5.824310541152954\n",
      "5.991987943649292 0.9749490082263945\n",
      "4.891247272491455\n",
      "5.058655261993408 0.01\n",
      "4.707363605499268\n",
      "4.874843120574951 0.01\n",
      "5.188270330429077\n",
      "5.355688810348511 0.99\n",
      "5.8498406410217285\n",
      "6.017403841018677 0.99\n",
      "5.422419548034668\n",
      "5.590126276016235 0.11389456763863563\n",
      "5.049240827560425\n",
      "5.216857433319092 0.01\n",
      "4.885504245758057\n",
      "5.053051471710205 0.99\n",
      "5.344442367553711\n",
      "5.5122971534729 0.7377723902463913\n",
      "4.984595060348511\n",
      "5.152095317840576 0.14204413769766688\n",
      "5.714842319488525\n",
      "5.8826093673706055 0.8124250829219818\n",
      "4.9831931591033936\n",
      "5.150696754455566 0.022413970809429883\n",
      "4.811014652252197\n",
      "4.978615045547485 0.9659480929374695\n",
      "4.792766571044922\n",
      "4.960325002670288 0.14233622900792398\n",
      "4.966344594955444\n",
      "5.1340248584747314 0.01\n",
      "7.353760004043579\n",
      "10.178070306777954 0.99\n",
      "4.723525524139404\n",
      "4.89124321937561 0.99\n",
      "5.15979266166687\n",
      "5.32728123664856 0.23882387969642876\n",
      "5.720825433731079\n",
      "5.8885157108306885 0.05517239694308955\n",
      "5.1451194286346436\n",
      "5.312657356262207 0.29668171256780623\n",
      "4.789489984512329\n",
      "4.957010507583618 0.01\n",
      "4.771799087524414\n",
      "4.939252614974976 0.01\n",
      "5.083175897598267\n",
      "5.250702857971191 0.09813958629965781\n",
      "4.878412485122681\n",
      "5.046149253845215 0.905402237176895\n",
      "4.761012077331543\n",
      "4.928410768508911 0.02085949917673133\n"
     ]
    }
   ],
   "source": [
    "modelx=WSDAN(num_classes=2, M=8, net='xception', pretrained=False).cuda()\n",
    "modelx.load_state_dict(torch.load('/kaggle/input/zzzzzz/mymodel/ckpt_x.pth')['state_dict'])\n",
    "modely=WSDAN(num_classes=2, M=8, net='efficientnet', pretrained=False).cuda()\n",
    "modely.load_state_dict(torch.load('/kaggle/input/zzzzzz/mymodel/ckpt_e.pth')['state_dict'])\n",
    "modelx.eval()\n",
    "modely.eval()\n",
    "predictions = predict_on_video_set(test_videos,modelx,modely)\n",
    "submission_df = pd.DataFrame({\"filename\": test_videos, \"label\": predictions})\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
